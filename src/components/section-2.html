<a id="section-2"></a>
<h2>Self-calibrating PIN-entering interface</h2>

<p> What if the buttons had no colors? In other words, what if the action-to-meaning mapping - between the position of the buttons (left/right) and their meaning (yellow/grey) - was not pre-defined?</p>

<p>An uninformed user would be quite confused about which button to press for which color, as button have no colors. But, for the sake of this explanation, let us assume the user arbitrarily choose a color for each button and use the interface that way - without telling the machine its color choice.</p>

<p>The machine is in trouble, it does not know what digit the user wants to enter and it does not know what the user means when pressing buttons. The reasoning used in <a href="#section-1">section 1</a> immediately collapses. Because we do not know the mapping between the button's position and the button's color, we can no longer follow the logical path: "If the user presses the left button, then they mean that their digit is currently yellow".</p>

<p>If anything, this line of reasoning turns into: "If the user presses the left button, then their digit is either yellow or grey with equal probability, thus I cannot make any decision." That sounds like a dead end. Before explaining how we solve this problem, you should experience how it feels to use such an interface and be able to arbitrarily choose buttons' colors.</p>

<p>In <a href="#interaction-2">Interaction 2</a>, the interface works the same way as in <a href="#interaction-1">Interaction 1</a> but no colors are displayed on the buttons. The colors are in your mind and you can assign them as you please. Providing there is at least one button for each color and that you stick with the same color pattern during the interaction, the machine will infer both your PIN and the colors of the buttons. Try the interface multiple times, entering different PINs and using different color patterns<d-footnote>We increased the number of button from 2 to 9 to augment the number of color combinations to choose from. Remember thought that the buttons can only be yellow or grey, they do not represent the digits (there is 9 buttons but 10 digits, so it could not map). <d-footnote>Don't worry, this is a common confusion and the fact we need this footnote is solely due to a wrong design choice from our side, that makes the button panel look like a phone dial.</d-footnote></d-footnote>.</p>

<include src="src/figures/vault_3x3.html"></include>

<p>It is an interesting feeling, isn't it? We are not used to having this level of choice when using the machines around us. To understand how this works, we shall look at the problem from a new angle</p>

<p>In section 1, we defined the following components: intent, meaning and action. We understood that an action conveys a meaning that can be used to infer an intent. And we have seen that this logical path requires a context that allows to deduce meanings from actions and intents from meanings. In this section, we are breaking one of these links, we do not known the mapping between the user's actions and their meanings. Using this terminology, we can state the challenge as follows: Can we identify user intent if the mapping between the user actions and their meanings is unknown?</p>

<p>But unknowns are scary. Let's reassure ourselves by listing the remaining known elements in our context. We know that users want to type one of ten possible digits, that they indicate the color of the digit they have in mind, and that they press buttons to send their feedback. All these assumptions remain, but one can be added that was hiding in plain sight.</p>

<p>We assumed all along that a button can have one and only meaning - yellow or grey (never none and never both). This assumption could barely be formulated because colors were visibly assigned on the buttons, it was too obvious to be noticed. The assumption that one button equals one meaning is so ingrained in our interaction with machines that we sometime forget it is part of the convention. We will measure breaches in this "yellow or grey" assumption to solve the self-calibration problem.</p>

<p>Because we know that the user is trying to type 1 of the 10 possible digits, we can make hypothesis. We can imagine 10 different worlds, each with the user trying to type one specific digit. One hypothetic world for each of the 10 digits. In each of these worlds, because we hypothetically enforce the digit the user is trying to type, we can easily infer the colors of the buttons using this simple reasoning: "If the user is trying to type a 1 (intent), then each time the user presses a button (action), we can assign the current color (meaning) of the digit 1 to that button". We are simply flipping the direction of inference in our logical chain from section 1.</p>

<p>By repeating this process for all digits between 0 and 9, we are left with 10 possible ways to assign colors to the buttons. And because the user is entering only one of the 10 possible digits, only one of the button-to-color maps will conform with our "yellow or grey" assumptions. For all other hypotheses, at some point during the interaction, it will look as if the user was pressing some buttons to mean <b>both</b> yellow and grey - which is a breach of our "yellow or grey" assumption, and enough to discard the digit associated with these hypotheses.</p>

<p>In other words, when, from the point of view of a given digit, the same button has been used to mean both yellow and grey, then that digit can not be the one the user has in mind because it is incompatible with our assumption that one button has one and only meaning. You can visualize this process directly on the explanatory interface below.</p>

<include src="src/figures/hood_3x3.html"></include>

<p>It is interesting to see how alternative interpretation of the same user's actions remain valid quite far into the identification process.</p>

<p>Notice also how, once the machine identified one digit, the colors of the buttons you pressed are displayed on the buttons and propagated to all hypotheses - see the right panel after a first digit is found. It becomes much easier to identify the next digits when those buttons are clicked again because we can reuse the reasoning of <a href="#section-1">section 1</a> with buttons of known colors.</p>

<p>This implies that the reasoning of <a href="#section-1">section 1</a> is equivalent to the reasoning of this section when all hypothesis agree on the button's colors. <a href="#section-1">Section 1</a> was only a particular case, and we can reframe it as follows: "<b>If</b> the user is trying to type a 1, and <i>if</i> the color of the button the user is pressing is different from the color applied on digit 1, <i>then</i> the same button is being used to express two different colors. <b>Thus</b> the user is not trying to enter the digit 1. <b>Else</b> they might be typing a 1". Convoluted but strictly equivalent and a powerful way to reframe human-machine interaction scenarios that enabled us to exploit a hidden "yellow or grey" assumption to solve the self-calibration challenge.</p>

<p>The remaining of this article considers how to scale this logic to continuous user's actions. In the next section, you will discover a version of our interface with no buttons. Instead you will place points on a 2D map and you will get to decide which areas are associated to which color.</p>
