<a id="section-5"></a>
<h2>Discussions</h2>


<p>Even when we are able to choose the way to use an interface, there usually is an explicit process for expressing that choice. We would first have to assign a color to each button using another interface (say a digital painting brush to color each button yellow or grey) and only then we could start using the interface following our coloring. In other words, there would be a dedicated and well defined interface to tell the machine the action-to-meaning mapping we want to use. But it is not the case here. The interface is self-calibrating, it understands both the digit and the colors at once, which differs from other adaptive human-computer interfaces. We will come back to this point later in section 5. For now, we ought to understand how we solve this problem.</p>

<p>Option (1) would quickly run into combinatioral issues as, in additional to considering all possible user's intents, we should also consider all possible button-to-color mappings. It would remain manageable with the 9 buttons used in <a href="#interaction-2">Interaction 2</a> with <d-math>2^9=512</d-math> possible user models. But it would become impossible to handle in section 3 when we move to continuous actions. Actions being never twice the same, the combinatoriality of user models will grow with the number of interaction (<d-math>N</d-math>) in <d-math>2^N</d-math>, and more importantly consistency will be impossible to assess due to a lack of constraints. We will come back to this notion of constraints.</p>

<p>Because the machine knows the colors applied on the digits<d-footnote>Curious minds might be asking how the machine decides what colors to apply on the digits. It is indeed a very stimulating problem but let's put it on the side for now and pretend we live in a world where the colors magically appear on the digits. We will discuss planning in section 5.</d-footnote>, when you click on the grey button, it can immediately discard all the yellow digits. By repeating the process 3 or 4 times, it can identify with certainty your first digit, and move to the second one.</p>


<p>

  Our consistency metric is the likelihood of the labelled data under a trained SVM classifier with a RBF kernel, and our statistical test is based on the minimum pairwise normalized likelihood between hypotheses, with a decision threshold of 0.9. 

In the end, one could say that there is nothing ground breaking in the way we solve this problem. We collect a dataset with a set of possible labels and we try to decide which set of labels best fit with the data. To do that we train and test the classifier on the data and pick the labels leading to the highest likelihood. And this is essentially what we do. The take home message is understand that there is a set of problem outthere that map to this.


It is an assumption that is implicit in all human-machine interaction scenarios and indeed in human-to-humam interactions

We calibrate for each target and we check which calibration makes sense


Talk of 5 grey vs 5 yellow, 50/50 probabilities, not biased

talk of latent variable

, one that does not need to know beforehand how to translate user's actions into their meanings, but can nonetheless infer what the user wants the machine to do.

First talk about the disssociateion between the signal and the action of the machine. Here the signal does not request an immediate action but rahter guide the machine towards the goals. Refine the wording from the introduction, highlight the differences.


planning
all extension in the thesis
representation
balance of classes (2x5) but out of balance classes can be used to more efficiently discriminate between the classes. discuss


Talk about Context-sensitive user interface and Adaptive_user_interface

human computer interfaces safe from onlookers
human robot interfaces
brain computer interfaces
neural response to stimuli
language games
phsycology / intent prediction (problem of mapping behavior to intention when the person does not act according to the norm (which is the calibration from society)), whcih can be applied for good and for bad
decryption? (check cell phone algorithms)


mathematical modeling + challenge to teach it
(we have shown that it works and gave a very exhasutive visualisation of how we solved this problem. Attempts at modelizing the problem have been done in the past (cite thesis). We explicitly do not want to provide a fomral  mathematical description of the problem, nor of how we implemented our solution. Why? Because we think the mathematcial description we have come up with before might not be the most appropriate. Our expectation is for some experienced readers to come up with a represenation that can explain all the phenomenon we put forward in this talk. We woudl bias them by providng our own view of the world here. It might needs to be rediscovered using a fresh mind.)
CHALLENGE

user acceptance and shift of bahavior in time
what problems can be used here (we need an interaction, a remote control does not really work because a clilck is supposed to be both the meaning and the intent)
computational cost
other metrics of consistency


The current paradigms in human-machine interaction either require the user to conform to the designer choices, to adapt to the machine. And a lot of research is done into how to optimize interface so they can be understood by everyone.

Another paradigms start by calibrating the machine to each users by collecting labelled data and training a classifier. This is more flexible and especially adapted to signal which human are not used to produce to control the world around them, such as brain signals, nerve inpulses, etc.

Maybe a third paradigms could be explore, where users can start interacting with a machine without calibration, and going their own way. It certainly is not practical for all applications, but maybe for some for good and to solve useful problems.

Finding them will reauire thinking outside the box of course but we might be surprised, let's try.

If a person is acting randomly with no aim and no consistent action to meaning model, then we cannot understand what they are trying to achieve. Appart fro behing a good political strategy, as most of us are in need of answers and this is confusing and keeping our focus on the behavior of such persons.


Presentation outcome
- incremental colloring patterns, building the meaning starting with 2 colors and then 3, etc. Maturational constraints -> link to language games
- use in pshycology tests. Can we infer intent from variable not explicitly represented in the problem (time of the day, if I slept well). Artificial tasks.
- can we have multiple tasks to solve to infer phsycological traits
- can we have a caregiver and the patient do the same test and infer one from the other
- people that have a hard time to express themselves
- use for saventurier, kangoroo competition
- use for people in hospitals that have writing disabilities
- neuron firing pattern to which stimuli. Mapping of the brain.
- use the machine to sample the real world. What an organism is trying to achieve
- automated discovery in science, learning representation that are consistent


Consistency is already a concept well established in ML, bit not always explicit like that. But it is encoded within the cost function optimized in most supervisef and unsupervised algorithm.

Between unsupervised learning and interactive learning. But never a known reward. Assumption of consistency.

Call for people to model this properly with math -> give example of https://guzey.com/how-life-sciences-actually-work/#almost-all-biologists-are-solo-founders-this-is-probably-suboptimal

Teaching: Challenge + Version of the interface that can be coded from a jupyter notebook, with tutorial hosted on binder

</p>

<p>
figure of the three areas of the interface

explaining the function that are below
- f(user, context) -> action
- f(action)-> meaning
- f(context,meaning)-> intent
</p>



<p>A key takehome message at this point is that a user meaning is just the interpretation of an action by an agent (machine or human). This interpretation can be seen as a function that take context and action as inputs and output a meaning. While this interpretation is usually pre-defined and shared between the machine and the human, what we do here is to remove that constraint and let the human choose freely its action ot meanign mapping wihtout telling the machine. And this interpreatation can be different between the emitter and the receiver depending on the context they both think they are evolving in. he process of actively testing the context for what the user migth be trying to achieve is the only way to find out if our interpreation is valid.</p>



<p>We can also cite <d-cite key="gregor2015draw"></d-cite>  external publications.</p>


<d-math>c = a^2 + b^2</d-math>


<d-code block="" language="css">
  #arrow-2 #arrow-head {
  fill: steelblue;
  }

  #arrow-2 #arrow-line {
  stroke: steelblue;
  }
</d-code>
